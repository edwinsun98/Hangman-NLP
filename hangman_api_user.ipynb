{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hangman NLP Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description:\n",
    "To tackle the hangman word guessing problem, I used the n-gram NLP probabilistic model. In this algorithm, a n-gram will be defined as a n-letter substring of a certain word instead of n separate words. To initialize and train the model, the algorithm first iterates through all the possible 1-gram to 9-gram substrings of all the words in the training dictionary and stores the substring frequencies in a map. The range is 1-gram to 9-gram substrings because most English words fall in the length of 1 to 9 letters and from further testing, I found out that any 10-gram or more will have negative effects on the accuracy of the algorithm. \n",
    "\n",
    "After storing the frequencies, the algorithm guesses the next letter for a given word by iterating through all the 1-gram to 9-gram substrings of the word with one missing letter.\n",
    "\n",
    "For example, the possible considerations of a 3-gram substring would be:\n",
    "[Letter][Letter][ _ ] or\n",
    "[Letter][ _ ][Letter] or\n",
    "[ _ ][Letter][Letter]\n",
    "\n",
    "Then, it tries to fit any possible non-guessed letter into that missing letter of the n-gram of the word by calculating the probability that the letter is in that position. This is accomplished by our frequency map that we initialized in the beginning. We store the probabilities of each letter occurring in all n-grams of the word and we take the letter with the maximum probability to be our guess.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "\n",
    "class HangmanAPI(object):\n",
    "    def __init__(self):\n",
    "        self.guessed_letters = []\n",
    "        \n",
    "        full_dictionary_location = \"words_250000_train.txt\"\n",
    "        self.full_dictionary = self.build_dictionary(full_dictionary_location)\n",
    "        \n",
    "        self.current_dictionary = []\n",
    "\n",
    "        # specifics for NLP n-gram probabilistic model\n",
    "        self.prob = {}\n",
    "        self.ngram = {}\n",
    "        self.ngram_lim = 9\n",
    "        self.weights = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "        self.initialize_ngrams(self.full_dictionary)            \n",
    "\n",
    "    def guess(self, word): # word input example: \"_ p p _ e \"\n",
    "\n",
    "        # clean the word so that we strip away the space characters\n",
    "        # replace \"_\" with \".\" as \".\" indicates any character in regular expressions\n",
    "        clean_word = word[::2].replace(\"_\",\".\")\n",
    "        \n",
    "        # convert to lowercase\n",
    "        clean_word = clean_word.lower()\n",
    "\n",
    "        self.prob.clear()\n",
    "\n",
    "        for c in range(ord('a'),ord('z')+1):\n",
    "            if(chr(c) not in self.guessed_letters):\n",
    "                self.prob[chr(c)] = 0\n",
    "\n",
    "        guess_letter = self.compute_ngrams(clean_word)\n",
    "\n",
    "        return guess_letter\n",
    "\n",
    "        \n",
    "    def initialize_ngrams(self, dict):\n",
    "        for word in dict:\n",
    "            for i in range(1, self.ngram_lim+1):\n",
    "                for j in range(0, len(word)-i+1):\n",
    "                    if(word[j:j+i] not in self.ngram):\n",
    "                        self.ngram[word[j:j+i]] = 0\n",
    "                    self.ngram[word[j:j+i]] += 1\n",
    "\n",
    "\n",
    "    def compute_ngrams(self, word):\n",
    "        for n in range (1, self.ngram_lim+1):\n",
    "            letters = {}\n",
    "            for c in range(ord('a'),ord('z')+1):\n",
    "                if(chr(c) not in self.guessed_letters):\n",
    "                    letters[chr(c)] = 0\n",
    "\n",
    "            letters_total = 0\n",
    "            for missing in range (0, n):\n",
    "                for i in range (0, len(word)-n+1):\n",
    "                    good = True\n",
    "                    for j in range (0, n):\n",
    "                        if(j == missing):\n",
    "                            good = good and (word[i+j] == '.')\n",
    "                        else:\n",
    "                            good = good and (word[i+j] != '.')\n",
    "                    if(good == True):\n",
    "                        for c in range(ord('a'),ord('z')+1):\n",
    "                            if(chr(c) not in self.guessed_letters):\n",
    "                                substr = \"\"\n",
    "                                for k in range (0, n):\n",
    "                                    if(k == missing):\n",
    "                                        substr += chr(c)\n",
    "                                    else:\n",
    "                                        substr += word[i+k]\n",
    "                                if(substr in self.ngram):\n",
    "                                    letters[chr(c)] += self.ngram[substr]\n",
    "                                    letters_total += self.ngram[substr]\n",
    "\n",
    "            for key, value in letters.items():\n",
    "                if(letters_total > 0):\n",
    "                    self.prob[key] += self.weights[n] * letters[key] / letters_total\n",
    "        \n",
    "        best_letter = ''\n",
    "        best_prob = 0\n",
    "        for key, value in self.prob.items():\n",
    "            if(value > best_prob):\n",
    "                best_prob = value\n",
    "                best_letter = key\n",
    "\n",
    "        return best_letter\n",
    "    \n",
    "    def build_dictionary(self, dictionary_file_location):\n",
    "        text_file = open(dictionary_file_location,\"r\")\n",
    "        full_dictionary = text_file.read().splitlines()\n",
    "        text_file.close()\n",
    "        return full_dictionary\n",
    "                \n",
    "    def start_game(self, practice=True, verbose=True):\n",
    "        # reset guessed letters to empty set and current plausible dictionary to the full dictionary\n",
    "        self.guessed_letters = []\n",
    "        self.current_dictionary = self.full_dictionary\n",
    "                         \n",
    "        response = self.request(\"/new_game\", {\"practice\":practice})\n",
    "        if response.get('status')==\"approved\":\n",
    "            game_id = response.get('game_id')\n",
    "            word = response.get('word')\n",
    "            tries_remains = response.get('tries_remains')\n",
    "            if verbose:\n",
    "                print(\"Successfully start a new game! Game ID: {0}. # of tries remaining: {1}. Word: {2}.\".format(game_id, tries_remains, word))\n",
    "            while tries_remains>0:\n",
    "                # get guessed letter from user code\n",
    "                guess_letter = self.guess(word)\n",
    "                    \n",
    "                # append guessed letter to guessed letters field in hangman object\n",
    "                self.guessed_letters.append(guess_letter)\n",
    "                if verbose:\n",
    "                    print(\"Guessing letter: {0}\".format(guess_letter))\n",
    "                    \n",
    "                try:    \n",
    "                    res = self.request(\"/guess_letter\", {\"request\":\"guess_letter\", \"game_id\":game_id, \"letter\":guess_letter})\n",
    "                except HangmanAPIError:\n",
    "                    print('HangmanAPIError exception caught on request.')\n",
    "                    continue\n",
    "                except Exception as e:\n",
    "                    print('Other exception caught on request.')\n",
    "                    raise e\n",
    "               \n",
    "                if verbose:\n",
    "                    print(\"Sever response: {0}\".format(res))\n",
    "                status = res.get('status')\n",
    "                tries_remains = res.get('tries_remains')\n",
    "                if status==\"success\":\n",
    "                    if verbose:\n",
    "                        print(\"Successfully finished game: {0}\".format(game_id))\n",
    "                    return True\n",
    "                elif status==\"failed\":\n",
    "                    reason = res.get('reason', '# of tries exceeded!')\n",
    "                    if verbose:\n",
    "                        print(\"Failed game: {0}. Because of: {1}\".format(game_id, reason))\n",
    "                    return False\n",
    "                elif status==\"ongoing\":\n",
    "                    word = res.get('word')\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"Failed to start a new game\")\n",
    "        return status==\"success\"\n",
    "        \n",
    "    def my_status(self):\n",
    "        return self.request(\"/my_status\", {})\n",
    "    \n",
    "    def request(\n",
    "            self, path, args=None, post_args=None, method=None):\n",
    "        if args is None:\n",
    "            args = dict()\n",
    "        if post_args is not None:\n",
    "            method = \"POST\"\n",
    "\n",
    "        # Add `access_token` to post_args or args if it has not already been\n",
    "        # included.\n",
    "        if self.access_token:\n",
    "            # If post_args exists, we assume that args either does not exists\n",
    "            # or it does not need `access_token`.\n",
    "            if post_args and \"access_token\" not in post_args:\n",
    "                post_args[\"access_token\"] = self.access_token\n",
    "            elif \"access_token\" not in args:\n",
    "                args[\"access_token\"] = self.access_token\n",
    "\n",
    "        time.sleep(0.2)\n",
    "\n",
    "        num_retry, time_sleep = 50, 2\n",
    "        for it in range(num_retry):\n",
    "            try:\n",
    "                response = self.session.request(\n",
    "                    method or \"GET\",\n",
    "                    self.hangman_url + path,\n",
    "                    timeout=self.timeout,\n",
    "                    params=args,\n",
    "                    data=post_args,\n",
    "                    verify=False\n",
    "                )\n",
    "                break\n",
    "            except requests.HTTPError as e:\n",
    "                response = json.loads(e.read())\n",
    "                raise HangmanAPIError(response)\n",
    "            except requests.exceptions.SSLError as e:\n",
    "                if it + 1 == num_retry:\n",
    "                    raise\n",
    "                time.sleep(time_sleep)\n",
    "\n",
    "        headers = response.headers\n",
    "        if 'json' in headers['content-type']:\n",
    "            result = response.json()\n",
    "        elif \"access_token\" in parse_qs(response.text):\n",
    "            query_str = parse_qs(response.text)\n",
    "            if \"access_token\" in query_str:\n",
    "                result = {\"access_token\": query_str[\"access_token\"][0]}\n",
    "                if \"expires\" in query_str:\n",
    "                    result[\"expires\"] = query_str[\"expires\"][0]\n",
    "            else:\n",
    "                raise HangmanAPIError(response.json())\n",
    "        else:\n",
    "            raise HangmanAPIError('Maintype was not text, or querystring')\n",
    "\n",
    "        if result and isinstance(result, dict) and result.get(\"error\"):\n",
    "            raise HangmanAPIError(result)\n",
    "        return result\n",
    "    \n",
    "class HangmanAPIError(Exception):\n",
    "    def __init__(self, result):\n",
    "        self.result = result\n",
    "        self.code = None\n",
    "        try:\n",
    "            self.type = result[\"error_code\"]\n",
    "        except (KeyError, TypeError):\n",
    "            self.type = \"\"\n",
    "\n",
    "        try:\n",
    "            self.message = result[\"error_description\"]\n",
    "        except (KeyError, TypeError):\n",
    "            try:\n",
    "                self.message = result[\"error\"][\"message\"]\n",
    "                self.code = result[\"error\"].get(\"code\")\n",
    "                if not self.type:\n",
    "                    self.type = result[\"error\"].get(\"type\", \"\")\n",
    "            except (KeyError, TypeError):\n",
    "                try:\n",
    "                    self.message = result[\"error_msg\"]\n",
    "                except (KeyError, TypeError):\n",
    "                    self.message = result\n",
    "\n",
    "        Exception.__init__(self, self.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results:\n",
    "With the training done on a 250,000 word dataset, this algorithm was able to predict words from a mutually exclusive dataset with an overall success rate of 63%, given a total of six tries to guess the word.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
